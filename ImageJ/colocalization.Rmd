---
title: "colocalization"
author: "YinCY"
date: "7/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Image Types 
Digital Images are two-dimensional grids of pixel intensities values with the width and height of the image being defined by the number of pixels in x (rows) and y (columns) direction. Thus, pixels (picture elements) are the smallest single components of images, holding numeric values – pixel intensities – that range between black and white. The characteristics of this range, i.e., the number of unique intensity (brightness) values that can exist in the image is defined as the bit–depth of the image and specifies the level of precision in which intensities are coded, e.g.: A 2–bit image has 2^2 = 4 tones: 00 (black), 01 (gray), 10 (gray), and 11 (white). A 4–bit image has 2^4 = 16 tones ranging from 0000 (0) to 1111 (16), etc. In terms of bits per pixel (bpp), the most frequent types of images (Image -> Type ->) that ImageJ deals with are:  

- 8-bit: Images that can display 256 (2^8) gray levels (integers only).  
- 16-bit: Images that can display 65536 (2^16) gray levels (integers only).  
- 32-bit: Images that can display 4294967296 (2^32) gray levels (real numbers). In 32-bit images, pixels are described by floating point values and can have ANY intensity value including NaN (Not a Number).  

RGB Color: Color images that can display 256 values in the Red, Green and Blue channel. These are 24-bit (2^3x8) images. RGB color images can also be 32-bit color images (24-bit color images with additional eight bits coding alpha blending values, i.e., transparency).  




# methods of colocalization analysis
## pixel intensity-based
In intensity-based correlation analyses, the pixel/voxel values in the image are directly used in the evaluation of spatial correlation. These can be broadly divided into two types: pixel matching colocalization analyses, and cross-correlation function based analyses.  

## one to one pixel matching
In pixel matching colocalization analyses, the intensity of a pixel in one channel is evaluated against the corresponding pixel in the second channel of a dual-color image, generally producing a scatterplot from which a correlation coefficient is determined. As these methods are straightforward, work very well with traditional widefield fluorescence imaging, and are very well founded as some of the earliest methods for measuring colocalization, they are very widely used. However, the one to one pixel matching means that there must be overlap of the signal from the two channels to demonstrate positive spatial correlation. This can be problematic for super-resolution microscopy images, where the improved resolution means that even close, strongly-correlated proteins may not produce sufficient overlap after imaging to work with these colocalization methods. Additionally, it is critical that the spatial resolution is reported when using this method, as the scale and resolution of the image can affect the results and their interpretation!  

### Pearson’s correlation coefficient
It is not sensitive to differences in mean signal intensities or range, or a zero offset between the two components. The result is +1 for perfect correlation, 0 for no correlation, and -1 for perfect anti-correlation. Noise makes the value closer to 0 than it should be.  
  
### Manders split coefficients
Proportional to the amount of fluorescence of the colocalizing pixels or voxels in each colour channel. You can get more details in Manders et al. Values range from 0 to 1, expressing the fraction of intensity in a channel that is located in pixels where there is above zero (or threshold) intensity in the other colour channel.  

## Cross-correlation function
Another type of intensity-based colocalization analyses utilize the Cross-correlation (CCF) to evaluate correlation between two channels. Exploring these techniques in the literature can be very confusing as there are effectively two different ways to apply the cross-correlation function to the problem of colocalization, and the distinction between them is often not well delineated in manuscripts discussing these techniques, with no consistent naming convention distinguishing one from the other. The two different ways that the CCF can be evaluated are either as a function of distance (spatial cross-correlation) or time (temporal cross-correlation). While these both use the same root function, they are two very different methodologies that have different imaging requirements, and that provide very different information about your molecules/proteins. 

In spatial cross-correlation, initially a measure of correlation of the two channels of a dual color image are evaluated in a manner similar to the pixel matching methods described above (though the exact function may vary). Then, one channel is shifted relative to the other (typically by one pixel) and then correlation is re-evaluated with that offset. This process is repeated across the entire image to generate a curve of correlation as a function of distance, as shown to the right. Like the scatterplot generating methods above, spatial cross-correlation methods work on single images and do not require more than one time point.  


## temporal cross-correlation 
In temporal cross-correlation two stained molecules are simultaneously monitored over time for coincident fluctuations in intensity. Coincidence of the fluorescence intensity fluctuations generally indicates molecular interaction. The key difference in temporal cross-correlation when compared to spatial cross-correlation, is that with temporal cross-correlation the data is shifted through time, not through space. Thus, **any temporal cross-correlation technique will require acquisition over time, and cannot be performed on single frame images or fixed samples**.  

The first, and best known, temporal cross-correlation technique is Fluorescence cross-correlation spectroscopy (FCCS). In FCCS a single diffraction limited volume is illuminated with two excitation lasers using a confocal microscope, and the emission of two fluorophores is recorded simultaneously over time. The two resulting fluorescent fluctuation graphs are then cross-correlated to determine if the particles are moving together, indicating an interaction. However, this technique does not need to be limited to a single focal volume, and more recent implementations of temporal cross-correlation apply this same methodology to multi-frame images, effectively evaluating the FCCS at each pixel of the image and averaging it. These image based temporal cross-correlation implementations are usually referred to as image cross-correlation spectroscopy (ICCS), however, this term has also been applied to spatial cross-correlation methods, which can make it very difficult to find the appropriate technique. If you’re ever unsure, the graphs generated from temporal cross-correlation methods will have their x-axis as time (usually labeled as τ or seconds), and not pixels or microns.  

## object-based colocalization 
In object-based colocalization analyses, the image is first segmented to separate the objects of interest from the background for both channels. Colocalization is then evaluated using these binary images, generally by comparing the area/volume of the intersection of the two images to the area/volume of: a) the union of the binary images, b) the difference of the binary images, c) one of the binary images unaltered, or d) a combination of these three. What you compare the intersection against will depend on the exact question being asked. Being able to tailor the analysis to your specific circumstances is one of the biggest advantages to object based-analysis.  

Additionally, basic object-based analyses can be performed easily without use of a plugin (though some are available to streamline the process) by doing the following: After segmentation of both images, the Image Calculator (Process › Image Calculator…) can be used to generate the intersection (AND operator), difference (difference or subtract operator), and the union (add or OR operator). Once these have been created, they can be analyzed using particle analysis to determine the area/volume, or analysis can be redirected to the original intensity data (Analyze › Set Measurements…) to evaluate the original pixel density within the particles. Generally, this type of object-based colocalization does require that there is overlap between your objects of interest from each channel. However, plugins have been developed that will perform distance analysis on the original binary images, removing the requirement for overlap between the two channels.  

## SMLM colocalization
Due to the unique nature of single-molecule localization microscopy images, as a list of localized points rather than a matrix of intensity values, traditional intensity or object-based colocalization techniques are insufficient for their analysis and thus SMLM images have their own unique colocalization methods. There are presently two categories of SMLM colocalization methods, neighboring colocalization and Voronoï-based colcoalization anlaysis.  

## Plugins for colocalization
### One to one pixel matching analyses
- Coloc2  
- JaCoP  
- Colocalization finder  

### Spatial cross-orrelation analyses  
- Colocalization by cross-correlation  
- JaCoP  

### Temporal cross-correlation analyses
- ImagingFCS  

### Object-based analyses
- JaCoP  
- Distance Analysis  

### SMLM analyses (no ImageJ implementation)  
- Coloc-Tesseler (standalone, not an ImageJ plugin)  
- ClusDoC (Matlab plugin)  


# Deconvolution
deconvolution corrects the systematic error of blur (loss of contrast in smaller features) in optical systems such as fluorescence microscopy images.  

## The problem, and the solution
Any optical image forming system, such as a microscope objective lens, has the nasty property of killing more and more contrast of smaller and smaller features, up to the resolution (diffraction) limit, after which there is no contrast (and thus no resolution). Large features are bright, but small features appear less contrasted and dimmer than they should. This is a systematic error, characterized by the Point Spread Function (PSF) of the optical system, which makes the image intensity information non-quantitative. If we can measure the PSF, or guess it, we can correct the raw image for it. Since it’s possible to correct such a systematic error, we should!  

Image contrast restoration by deconvolution is a way to correct the systematic error of contrast loss in an image recording system, such as a microscope objective lens or telescope mirror or lens. We try to reverse the effects of blur in the recorded image, caused by convolution (blur, smearing, loss of contrast of small features) of the real image due to the imaging point spread function (PSF).  

Image contrast restoration by deconvolution is an important systematic error correction step for quantitative measurement of image pixel intensities in analysis workflows. If we don’t correct this systematic error, the results of the image intensity analysis could be very much more wrong than if we correct the images before analysis. It’s the same as zeroing a scale before weighing something.  














